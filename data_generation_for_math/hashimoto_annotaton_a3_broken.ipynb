{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a5bfac-1077-41c6-ab5f-3a255ceb5a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "import subprocess\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from sympy import symbols, Function\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions import gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4188d1f4-b48d-455e-83af-8d496de35e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "purpose = \"- The data is for expressions related to neural ordinary differential equation and holographic quantum chromodynamics\"\n",
    "\n",
    "annotation_name = 'a3'\n",
    "math_text = \"\"\"a_{i}(t)=\\frac{\\partial \\mathcal{L}}{\\partial x_{i}(t)}\"\"\"\n",
    "\n",
    "paper_short_name = 'hashimoto'\n",
    "dataset_name = f'dataset'\n",
    "\n",
    "base_name = \"2021_Hashimoto_Neural_ODE_and_holographic_QCD_PUB\"\n",
    "work_bucket = \"AdS-CFT\"\n",
    "project_folder = \"diygenomics-projects\"\n",
    "sub_category = \"math\"\n",
    "\n",
    "model = 'gpt-4'\n",
    "output_file = f'{paper_short_name}_{annotation_name}.py'\n",
    "\n",
    "# A1 and A2 feed A4 and A8; A3 feeds A5, A6, and A7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3e5d1c-96f6-47b6-915c-921f702e5e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = os.getenv('DATA_PATH')\n",
    "file_path = lambda *args: os.path.join(data_path, project_folder, sub_category, work_bucket, base_name, 'mathpix', 'generated_code', *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b414ada4-7337-4705-bf2e-9cc01c4ca910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(file_path(), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c45480-38d9-45fe-952f-cd4d2b199b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_prompt = f\"\"\"You are an expert mathematician and data scientist.\n",
    "- I want to generate a dataset as input for a math expression\n",
    "- The data need to return results that are not NaN or None\n",
    "{purpose}\n",
    "- Please format your response in JSON. You only speak JSON. Do not write text that isn't JSON.\n",
    "- The output of this will be used as input for another expression. \n",
    "- Be consice in your output so that it can be feed into the next expression.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a98c856-7bce-4390-b6f6-b683a116e8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = gpt.chat_create(dataset_prompt, math_text, model, output_json=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a908349-6cac-4891-8ac4-f64594cb126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': [{'time': 1, 'x_i(t)': 0.5, 'a_i(t)': 0.2},\n",
       "  {'time': 2, 'x_i(t)': 0.6, 'a_i(t)': 0.3},\n",
       "  {'time': 3, 'x_i(t)': 0.7, 'a_i(t)': 0.4},\n",
       "  {'time': 4, 'x_i(t)': 0.8, 'a_i(t)': 0.5},\n",
       "  {'time': 5, 'x_i(t)': 0.9, 'a_i(t)': 0.6}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5d7663-70b6-4105-8400-3a13b9386750",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_plus_data = f'math expression: {math_text}\\ndataset: {dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3564743e-52cc-41ce-8149-c22d547e2828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt_primer = \"\"\"You are an expert mathematician, data scientist and prompt engineer.\"\"\"\n",
    "\n",
    "user_prompt_primer = f\"\"\"I have this math expression: \n",
    "\n",
    "{math_text}\n",
    "\n",
    "I have this dataset: \n",
    "\n",
    "{dataset}\n",
    "\n",
    "- Make sure that you use the variable name 'dataset'.\n",
    "- Please help me create a prompt that will allow an LLM to generate python code that can be executed to print the results of applying \n",
    "the dataset to the python code.\n",
    "- Do not include any unnecessary comments. \n",
    "- Only include the required output that can be directly used as input to another call.\n",
    "- Do not add anything prior to providing the prompt. \n",
    "- Only include the prompt.\n",
    "- Do not say Sure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770928a6-588d-49d2-8091-f8342850ac86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# user_prompt = gpt.chat_create(system_prompt_primer, user_prompt_primer, model, output_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7238d55e-bf29-4278-8d4b-ff70fc779bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_prompt = f\"\"\"You are an expert mathematician and data scientist.\n",
    "- Please format your response in the python coding language. You only speak python. Do not write text that isn't python.\n",
    "- Do not include any comments in your code.\n",
    "- Do not include the dataset in your response. \n",
    "- The dataset variable name will be {dataset_name}.\n",
    "{purpose}\n",
    "- Make sure that the generated code prints the results.\n",
    "- Check your work and make that the dataset works with the python code that you provide.\n",
    "- Check the first key in the dataset. \n",
    "- The first key is '{next(iter(dataset))}'. \n",
    "- It is very important that you make sure that you access the dataset dict with the provided key -> '{next(iter(dataset))}'.\n",
    "- Make sure that your code prints results that were fully executed and return numbers or lists of numbers\n",
    "\"\"\"\n",
    "\n",
    "# user_prompt = f\"\"\"Generate Python code that takes as input a list of dictionaries, where each dictionary represents a data point in a dataset. \n",
    "# Each dictionary has three key-value pairs: 'time', 'x_i', and 'a_i'. \n",
    "# The code should implement the mathematical expression {math_text}. \n",
    "# Use the following dataset as an example for testing:\n",
    "# {dataset}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdfdde2-55be-48b7-bcb9-d9061c5b5097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_code = gpt.chat_create(code_prompt, math_plus_data, model, output_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea1cf8e-0844-4751-a931-9481a0085ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "import pandas as pd\n",
       "\n",
       "df = pd.DataFrame(dataset['dataset'])\n",
       "\n",
       "print(df)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(python_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f6ae35-709d-4808-90f3-9c511bfe20a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretty_dataset = json.dumps(dataset, indent=4)\n",
    "\n",
    "with open(file_path(output_file), 'w') as f:\n",
    "    f.write(f'{dataset_name} = {pretty_dataset}\\n\\n')\n",
    "    f.write(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7495b63-41d1-4cfd-974c-b8c142f943d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:    time  x_i(t)  a_i(t)\n",
      "0     1     0.5     0.2\n",
      "1     2     0.6     0.3\n",
      "2     3     0.7     0.4\n",
      "3     4     0.8     0.5\n",
      "4     5     0.9     0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command = ['python', file_path(output_file)]\n",
    "result = subprocess.run(command, text=True, capture_output=True)\n",
    "\n",
    "output = result.stdout\n",
    "error_output = result.stderr\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"Error output:\", error_output)\n",
    "else:\n",
    "    print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e0501-bef0-413c-8655-acc9697e480a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
