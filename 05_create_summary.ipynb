{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7c542-8f10-4d2c-adfb-e5b0f83376cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functions import gpt\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dc042-06ea-46d6-b51a-bd8a2ef8efce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_file = '2021_Wightman-Posthuma_A_genomewide_association_study_with_112_563_individuals_identifies_new_risk_loci_for_Alzheimers_disease'\n",
    "external_id = '2023_05_02_27142069922ab9506d3dg'\n",
    "input_file = f'truth_{external_id}.chunks.csv'\n",
    "output_file = f'gpt_summary_{external_id}.csv'\n",
    "\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "file_path = lambda *args: os.path.join(data_path, 'diygenomics-projects', 'experiment-a', \n",
    "                                       original_file, 'mathpix', *args)\n",
    "\n",
    "model = 'gpt-4' # 'gpt-3.5-turbo' # 'gpt-4'\n",
    "index_col = 'uuid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a8ca5-0ee1-46c1-a93c-edb3f6d97dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path(input_file), index_col=index_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c6a98-b6af-4743-949f-ea5718573e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_system_prompt = \"\"\"Extract up to 20 topics and their associated keywords (up to 5 per topic) from a research paper. \n",
    "                        Group synonyms and closely related words together. Prioritize technical information, \n",
    "                        and include only the most relevant keywords. Consider the context of the text when generating topics. Output \n",
    "                        the results as a JSON object with topics as keys with a count of occurrences of the topic in the text and a \n",
    "                        dictionary containing a list of keywords. Only provide JSON output. Do not output anything other than JSON. \n",
    "                        Check your output and make sure that it is in this format {\"Speed\": {\"count\": 2, \"keywords\": ['rapid development', 'technology advancement']}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa30fa-b4eb-45d3-a519-90019823a97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_errors = {}\n",
    "general_errors = {}\n",
    "\n",
    "def extract_topics(row):  \n",
    "    response = None\n",
    "\n",
    "    if len(row['text']) > 0:\n",
    "        possible_response = gpt.chat_create(topic_system_prompt, row['text'], model, output_json=True)\n",
    "        if 'json_error' in possible_response:\n",
    "            json_errors[row.name] = response\n",
    "        elif 'general_error' in possible_response:\n",
    "            general_errors[row.name] = response\n",
    "        else:\n",
    "            response = possible_response\n",
    "        \n",
    "    return response\n",
    "\n",
    "df['topics'] = df.progress_apply(lambda row: extract_topics(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1508bc6-dd31-44ba-9575-cb6285b9bd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file_path('gpt_topic_json_errors.json'), 'w') as file:\n",
    "    json.dump(json_errors, file)\n",
    "    \n",
    "with open(file_path('gpt_topic_general_errors.json'), 'w') as file:\n",
    "    json.dump(general_errors, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40654a87-2deb-4435-9a77-988040f90277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_topics = {}\n",
    "for d in list(df['topics']):\n",
    "    try:\n",
    "        for key, value in d.items():\n",
    "            if key in combined_topics:\n",
    "                combined_topics[key]['keywords'] = list(set(combined_topics[key]['keywords'] + value['keywords']))\n",
    "                prior_count = combined_topics[key]['count'] if 'count' in combined_topics[key] else 0\n",
    "                combined_topics[key]['count'] = prior_count + value['count'] if 'count' in value else 0\n",
    "            else:\n",
    "                combined_topics[key] = value\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c663e8-7aed-4a5b-86f0-144cea2368b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file_path('topics.json'), 'w') as file:\n",
    "    json.dump(combined_topics, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44deb9f-af9e-46eb-83f9-f7ad5e6c2f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_system_prompt = \"\"\"Summarize the given text in a single paragraph containing no more than 8 sentences from a trascription \n",
    "                        taken from a scientific research paper.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa3724-b804-4c30-9ba0-282f720b8edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_errors = {}\n",
    "\n",
    "def extract_summaries(row):  \n",
    "    response = None\n",
    "\n",
    "    if len(row['text']) > 0:\n",
    "        possible_response = gpt.chat_create(summary_system_prompt, row['text'], model, output_json=False)\n",
    "        if 'general_error' in possible_response:\n",
    "            general_errors[row.name] = response\n",
    "        else:\n",
    "            response = possible_response\n",
    "        \n",
    "    return response\n",
    "\n",
    "df['summary'] = df.progress_apply(lambda row: extract_summaries(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d85e8-f633-4657-b1e6-e8010e87c805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file_path('gpt_summary_general_errors.json'), 'w') as file:\n",
    "    json.dump(general_errors, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100268e-a6da-48b5-8e31-ca2639e73df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['topics'].to_csv(file_path(f'gpt_topics_{external_id}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f417ed-39ba-4792-ac3c-afb2b269ade8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['summary'].to_csv(file_path(f'gpt_summary_{external_id}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf43aed0-94c2-4f53-a638-b1657de56a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_of_summaries_system_prompt = \"\"\"Summarize the given summaries in a single paragraph containing no more than 8 sentences \n",
    "                                    from a trascription taken from a scientific research paper.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8015ab-162e-4f05-9a9a-669247011090",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_error = None\n",
    "summary_of_summaries = None\n",
    "summaries = ' '.join(str(value) for value in list(df['summary']))\n",
    "\n",
    "possible_response = gpt.chat_create(summary_of_summaries_system_prompt, summaries, model, output_json=False)\n",
    "if 'general_error' in possible_response:\n",
    "    general_errors = response\n",
    "else:\n",
    "    summary_of_summaries = possible_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960505b5-50ba-4bbd-afa0-3d442a1df912",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path('summary_of_summaries.txt'), 'w') as file:\n",
    "    file.write(summary_of_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdf9b9-a7eb-4d53-b00f-4e7a0ab3acd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
