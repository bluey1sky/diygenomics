{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8513d1-36fe-42ff-8d7f-e4e1d9a2735c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import uuid\n",
    "\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3293082b-fae1-469e-86d4-da3e0c68adcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_name = 'mel_swan'\n",
    "project_name = 'diygenomics'\n",
    "\n",
    "original_file = '2021_Wightman-Posthuma_A_genomewide_association_study_with_112_563_individuals_identifies_new_risk_loci_for_Alzheimers_disease'\n",
    "external_id = '2023_05_02_27142069922ab9506d3dg'\n",
    "input_file = f'{external_id}.lines.json'\n",
    "output_file_lines = f'truth_{external_id}.lines.csv'\n",
    "output_file_chunks = f'truth_{external_id}.chunks.csv'\n",
    "\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "file_path = lambda *args: os.path.join(data_path, 'eric-client-projects', product_name, project_name, 'experiment-a', \n",
    "                                       original_file, 'mathpix', *args)\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "max_chunk_size = 6000\n",
    "overlap_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444d6851-04e3-49aa-9258-7986685de300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(file_path(input_file), 'r') as file:\n",
    "    raw_article = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8efaa5-8a2c-4e86-849e-da297998512f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for page in raw_article['pages']:\n",
    "    page_number = page['page']\n",
    "    for line in page['lines']:\n",
    "        text = LatexNodes2Text().latex_to_text(line['text'])\n",
    "        line_number = line['line']\n",
    "        column_number = line['column']\n",
    "        \n",
    "        data.append({'page_number': page_number, 'line_number': line_number, 'column_number': column_number, 'text': text})\n",
    "        \n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62639c90-3c7d-4ff9-b62a-2e8844017544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['uuid'] = [uuid.uuid4() for _ in range(len(df))]\n",
    "df.set_index('uuid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35efdc6e-3e65-4f0a-a26f-dfe5707ad3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(file_path(output_file_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5e8138-2dff-4528-98f4-6847e94aedc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "current_chunk = \"\"\n",
    "start_line_uuid = None\n",
    "stop_line_uuid = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    current_uuid = index\n",
    "\n",
    "    if current_chunk == \"\":\n",
    "        start_line_uuid = current_uuid\n",
    "        current_chunk = text\n",
    "    else:\n",
    "        current_chunk += \" \" + text\n",
    "\n",
    "    if len(current_chunk) > max_chunk_size:\n",
    "        overlap_words = current_chunk.split()[-overlap_size:]\n",
    "        stop_line_uuid = current_uuid\n",
    "        data.append({'start_line_uuid': start_line_uuid, 'stop_line_uuid': stop_line_uuid, 'text': current_chunk})\n",
    "        start_line_uuid = current_uuid\n",
    "        current_chunk = \" \".join(overlap_words)\n",
    "\n",
    "if current_chunk != \"\":\n",
    "    stop_line_uuid = current_uuid\n",
    "    data.append({'start_line_uuid': start_line_uuid, 'stop_line_uuid': stop_line_uuid, 'text': current_chunk})\n",
    "    \n",
    "df_chunks = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c55df6-405e-443b-9fbc-4cf9aeefc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks['uuid'] = [uuid.uuid4() for _ in range(len(df_chunks))]\n",
    "df_chunks.set_index('uuid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea874cf2-823e-4e0e-9c44-4e5ad7f45278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_chunks.to_csv(file_path(output_file_chunks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
